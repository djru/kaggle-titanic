{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Titanic Survival Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
   "execution_count": 12,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train = pd.read_csv('../input/train.csv')",
   "execution_count": 13,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Drop columns that logically shouldn't matter or are mostly null:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train.drop(['PassengerId', 'Name', 'Cabin', 'Embarked', 'Ticket', 'Fare'], axis=1, inplace=True)",
   "execution_count": 14,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Convert sex into a dummy varible so we can regress on it:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train['Male'] = pd.get_dummies(train['Sex'])['male']\ntrain.drop('Sex', axis=1, inplace=True)",
   "execution_count": 15,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Let's create another dummy that indicates whether they were a child or not:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train['Child'] = train.apply(lambda row: row['Age'] <= 12.0, axis=1)\ntrain.drop('Age', inplace=True, axis=1)",
   "execution_count": 16,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Instead of regressing on family sizes, let's create a dummy indicating whether the person had any family",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train['SibsSp'] = train.apply(lambda row: row['SibSp'] > 0, axis=1)\ntrain['Parch'] = train.apply(lambda row: row['Parch'] > 0, axis=1)",
   "execution_count": 17,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Separate y values:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "labels = train['Survived']\ntrain.drop('Survived', axis=1, inplace=True)",
   "execution_count": 18,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Import various models to try out:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import KFold",
   "execution_count": 19,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Do a KFold validation for each of our candidate models, then print the best:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "splits = KFold(n_splits=5, shuffle=True)\nfor model in [RandomForestClassifier(), SVC(), DecisionTreeClassifier(), GaussianNB()]:\n    print(model)\n    print(np.mean([model.fit(train.iloc[tr], labels.iloc[tr]).score(train.iloc[te], labels.iloc[te]) for tr, te in splits.split(train, labels)]))",
   "execution_count": 20,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "It definitely looks like Support Vectors are performing the best here, so that is the model we will use for our predictions on the test data.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Performing data massaging on the test data:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test = pd.read_csv('../input/test.csv')\ntest.drop(['Name', 'Cabin', 'Embarked', 'Ticket', 'Fare'], axis=1, inplace=True)\ntest['Male'] = pd.get_dummies(test['Sex'])['male']\ntest.drop('Sex', axis=1, inplace=True)\ntest['Child'] = test.apply(lambda row: row['Age'] <= 12.0, axis=1)\ntest.drop('Age', inplace=True, axis=1)\ntest['SibsSp'] = test.apply(lambda row: row['SibSp'] > 0, axis=1)\ntest['Parch'] = test.apply(lambda row: row['Parch'] > 0, axis=1)",
   "execution_count": 21,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Predict the survival values and write them to a csv file:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "submission = pd.DataFrame({\n        \"PassengerId\": test['PassengerId'],\n        \"Survived\": SVC().fit(train, labels).predict(test.drop('PassengerId', axis=1))\n    })\nsubmission.to_csv('titanic.csv', index=False)",
   "execution_count": 22,
   "outputs": [],
   "metadata": {}
  }
 ]
}